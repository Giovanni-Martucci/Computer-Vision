{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial \"Texture on OpenCV\"\n",
    "\n",
    "In questo tutorial vedremo come implementare alcune funzioni per la trattazione delle Texture tramite l'utilizzo di OpenCV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cosa sono le Texture?\n",
    "\n",
    "<font size=\"3\">Le Texture sono l’insieme di proprietà e caratteristiche della superficie di un oggetto. Tali proprietà possono essere la quantità, la forma, l’aspetto, la posizione delle sue parti elementari, ecc...\n",
    "<br><br>I prinicpali task delle Texture sono:</font><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "- **Detection**: la Texture Detection in un'immagine è l’operazione che tende a rilevare le zone in un'immagine con texture differenti,trovandone i bordi;<br><br>\n",
    "- **Sintesi**: è la tecnica che analizza la natura stocastica della texture, con lo scopo di riuscirne a catturare, in maniera più o meno diretta, il processo generativo intrinseco che la caratterizza. In questo modo si riescono a riprodurre, nella fase di sintesi, texture che percettivamente appaiono differenti dall'originale pur appartenendo alla stessa classe statistica di base;<br><br>\n",
    "- **Classification**: Essa fa parte dei task principali ed è strettamente legata all’operazione di analisi. E' un operazione abbastanza difficile in quanto la texture può apparire in un'immagine in modi differenti tra loro, e ciò dipende ovviamente dal grado di luminosità, dall'angolazione, dalla scala di risoluzione ecc...</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Nel dettaglio andremo a vedere i task principali delle Texture.<br><br>\n",
    "\n",
    "Iniziamo con la classificazione delle texture tramite le features di Haralick. In particolare il concetto fondamentale coinvolto nel calcolo delle funzionalità di Haralick Texture è la matrice di ricorrenza del livello di grigio o GLCM.<br>\n",
    "La matrice di ricorrenza del livello di grigio (GLCM) utilizza il concetto di adiacenza nelle immagini. L'idea di base è che cerca coppie di valori di pixel adiacenti che si verificano in un'immagine.\n",
    "<br><br>Vi sono quattro tipi di adiacenza:<br><br>\n",
    "- Da sinistra a destra;\n",
    "- Dall'alto al basso;\n",
    "- In alto da sinistra in basso a destra;\n",
    "- Dall'alto in alto a sinistra in basso. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Matrix.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Haralick Texture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"><br>Import the necessary packages:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import mahotas as mt\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> Carichiamo il training set ed inizializziamo due liste che conterranno i vettori di features e le etichette</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training dataset\n",
    "train_path = \"textH/dataset/train\"\n",
    "train_names = os.listdir(train_path)\n",
    "\n",
    "# empty list to hold feature vectors and train labels\n",
    "train_features = []\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=\"3\">Implementiamo la funzione che andrà ad estrarre le features:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract haralick textures from an image\n",
    "def extract_features(image):\n",
    "    # calculate haralick texture features for 4 types of adjacency\n",
    "    textures = mt.features.haralick(image)\n",
    "\n",
    "    # take the mean of it and return it\n",
    "    ht_mean  = textures.mean(axis=0)\n",
    "    return ht_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=\"3\">Con la funzione **mt.features.haralick()** andiamo ad estrarre le features per tutti e 4 i tipi di adiacenza;<br><br>Andiamo poi a calcolare la media di tutti e 4 i tipi di GLCM, tramite **mean()**.<br><br> Infine ritorniamo il vettore delle feautres il quale descrive la texture.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font size=\"3\">Ora passiamo alla fase di training:<br><br>\n",
    "<font size=\"3\">\n",
    "Scorrendo sulle etichette di allenamento che abbiamo appena incluso nella directory di allenamento prendiamo tutti i file con estensione jpg (per ogni etichetta alla volta) e analiziamo ogni file uno alla volta.<br><br>\n",
    "Tramite le funzioni *cv2.imread()* e *cv2.cvtColor()* andiamo a leggere e convertire ciascuna immagine in scala di grigi.<br><br> Richiamiamo la funzione implementata precedentemente per estrarre le texture Haralick dall'immagine, per ogni immagine, in scala di grigi aggiungendoli alla lista *train_features* e aggiungendo l'etichetta in *train_labels*.\n",
    "<font><font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures..\n",
      "Processing Image - 1 in wood\n",
      "Processing Image - 2 in wood\n",
      "Processing Image - 3 in wood\n",
      "Processing Image - 4 in wood\n",
      "Processing Image - 5 in wood\n",
      "Processing Image - 1 in grass\n",
      "Processing Image - 2 in grass\n",
      "Processing Image - 3 in grass\n",
      "Processing Image - 4 in grass\n",
      "Processing Image - 5 in grass\n",
      "Processing Image - 1 in brick\n",
      "Processing Image - 2 in brick\n",
      "Processing Image - 3 in brick\n",
      "Processing Image - 4 in brick\n",
      "Processing Image - 5 in brick\n",
      "Processing Image - 1 in rock\n",
      "Processing Image - 2 in rock\n",
      "Processing Image - 3 in rock\n",
      "Processing Image - 4 in rock\n",
      "Processing Image - 5 in rock\n"
     ]
    }
   ],
   "source": [
    "# loop over the training dataset\n",
    "print(\"[STATUS] Started extracting haralick textures..\")\n",
    "for train_name in train_names:\n",
    "    cur_path = train_path + \"/\" + train_name\n",
    "    cur_label = train_name\n",
    "    i = 1\n",
    "\n",
    "    for file in glob.glob(cur_path + \"/*.jpg\"):\n",
    "        print(\"Processing Image - {} in {}\".format(i, cur_label))\n",
    "        # read the training image\n",
    "        image = cv2.imread(file)\n",
    "\n",
    "        # convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # extract haralick texture from the image\n",
    "        features = extract_features(gray)\n",
    "\n",
    "        # append the feature vector and label\n",
    "        train_features.append(features)\n",
    "        train_labels.append(cur_label)\n",
    "\n",
    "        # show loop update\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Vediamo dal risultato che tutte le immagine sono state processate. (Nell'esempio abbiamo 5 immagini per ogni tipo di classe).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font size=\"3\">Procediamo con la creazione del classificatore tramite la funizione *LinearSVC()* importata dalla libreria *sklearn*:<br>- Impostando il *random_state* a 9: controlla la generazione di numeri pseudo casuali per mescolare i dati per la discesa a doppia coordinata;<br>- *tol*: indica la tolleranza per i criteri di arresto;<br>- *verbose* settato a 1: abilita l'output dettagliato;<br>- *max_iter*: indica il massimo numero di iterazioni da eseguire.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier\n",
    "print(\"[STATUS] Creating the classifier..\")\n",
    "clf_svm = LinearSVC(random_state=9,tol=1e-5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=\"3\">Adesso si procede adattando le features e le labels di allenamento al classificatore</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training data and labels\n",
    "print(\"[STATUS] Fitting data/label to model..\")\n",
    "clf_svm.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font size=\"3\">Infine viene testato il classificatore sui dati di test:<br><br>\n",
    "inseriamo il path delle immagini di test in *test_path* e poi tramite il *for* si andranno a leggere le immagini singolarmente , tramite *cv2.imread()* , si procede con la conversione in scala di grigi. Poi si estraggono le features dalle immagini in scala di grigi e tramite la funzione *predict()* si predirrà l'etichetta di appartenenza.<br><br>Infine tramite *cv2.putText()* inseriremo il testo della predizione nell'immagine sotto analisi e tramite *cv2.imshow()* mostreremo il risultato della previsione.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the test images\n",
    "test_path = \"dataset/test\"\n",
    "for file in glob.glob(test_path + \"/*.jpg\"):\n",
    "    # read the input image\n",
    "    image = cv2.imread(file)\n",
    "\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # extract haralick texture from the image\n",
    "    features = extract_features(gray)\n",
    "\n",
    "    # evaluate the model and predict label\n",
    "    prediction = clf_svm.predict(features.reshape(1, -1))[0]\n",
    "\n",
    "    # show the label\n",
    "    cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "    print(\"Prediction - {}\".format(prediction))\n",
    "\n",
    "    # display the output image\n",
    "    cv2.imshow(\"Test_Image\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
